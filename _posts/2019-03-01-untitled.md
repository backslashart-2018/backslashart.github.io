We built on top of the pad sounds we shared a couple weeks ago and focused on building a vocal track. First, we flattened the dataset down to around 800 unique traits. Realizing that it‘s impossible to load all of them into Ableton, we started off with 44 names of the data columns. These are phrases like “body type”,  “diet”, “At what age did you start to play your first instrument?” so on. We then used Google Cloud‘s Text-to-Speech API to generate the synthetic voice samples using the voice “en-US-Wavenet-C”. After loading them into Ableton in the session view, we created a Max device that triggers these sounds at a random interval between 10 and 15 seconds.

![](/assets/images/vocal.jpeg)

