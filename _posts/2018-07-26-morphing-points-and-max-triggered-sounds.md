---
layout: post
title: "Morphing Points and Max-triggered Sounds"
date:   2018-07-12 15:26:00
categories: Max
---

![Max playing genetic sequence](/assets/images/max-playing-genetic-seq.png)

This past week, we had a deepened conversation about visualizing new humans with the Tajima team. With handcrafted superpowers and meshed data using various data sources, we showed Mika what PCA, t-SNE, and truncated SVD would each look like. They look great, but the question that follows is how do we create endless, moving points such that they never cease to stop and we are still able to see new things? With the discussions, we found there are two paradigms going forward. One is to move from one dimensionality-reduction technique to the next (or different steps in t-SNE). The other model is to keep changing the features included so the points keep moving. There are philosophical arguments to be made on both sides. On one hand, one may argue that the first direction shows how machines see things we humans never see about these “Frankenstein-ed” individuals. On the other hand, it is also true that the second direction places the emphasis on the multi-faceted nature of human beings -- there are never enough features to fully capture a person. By including different features, we show that there are always new perspectives to see someone. 

We came to the conclusion that we will be able to make a better decision when we see both so we will be creating examples of technique shift and feature shift visualizations in the coming weeks. 

On a similar note, Jacob brought up the idea of using generative adversarial networks (GANs) to create infinite visualizations. Mika, Eric, and Howie were all intrigued by this idea of two digital brains competing and interacting with each other. The idea is that we could either feed it a number of data points of meshed humans and ask it to create new data points of “similar-looking” humans, or we can feed it pictures of visualized clusters. We don‘t know what the result would actually look like so that’s another idea to experiment with.

In the world of sound, Christy is rapidly learning Max and created a Max program (pictured above) in an attempt to make sounds out of genetic sequences, by mapping [SNP](https://en.wikipedia.org/wiki/DbSNP) to pitch, genome position to duration and the two [allels](https://en.wikipedia.org/wiki/Allele) to a few [General MIDI](https://en.wikipedia.org/wiki/General_MIDI) sounds. The result is this bizarre, somewhat random yet steady flow of sounds consisting of bird tweets, flute, piano, and drums. Though we don‘t imagine this specific program to be part of the final art piece, it gave us a lot of ideas for how we might create aural elements that fit with the visually morphing points. One idea is to use chord progressions to simulate as new clusters form. Another idea is to create a signature sound for each individual. There are a lot of questions to be asked relating to the material used and the position of speakers, but we are moving closer and closer to the goal and, most importantly, having fun.